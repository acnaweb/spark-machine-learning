{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificacao de SPAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import IDF, HashingTF, Tokenizer\n",
    "from pyspark.ml.classification import NaiveBayes, NaiveBayesModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spSession = SparkSession.builder.master(\"local\").appName(\"classifier-spam\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data/SMSSpamCollection.csv MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spamRRR = sc.textFile(\"data/SMSSpamCollection.csv\")\n",
    "spamRRR.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ham,Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...,,,,,,,,,',\n",
       " 'ham,Ok lar... Joking wif u oni...,,,,,,,,,,',\n",
       " 'ham,U dun say so early hor... U c already then say...,,,,,,,,,,',\n",
       " \"ham,Nah I don't think he goes to usf, he lives around here though,,,,,,,,,\",\n",
       " 'ham,Even my brother is not like to speak with me. They treat me like aids patent.,,,,,,,,,,']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spamRRR.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré processamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformToVector(line):\n",
    "    lineList = line.split(\",\")\n",
    "    smsType = 0.0 if lineList[0] == \"ham\" else 1.0\n",
    "    \n",
    "    return [smsType, lineList[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 'Go until jurong point'], [0.0, 'Ok lar... Joking wif u oni...']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spamRRR2 = spamRRR.map(transformToVector)\n",
    "spamRRR2.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|             message|\n",
      "+-----+--------------------+\n",
      "|  0.0|Go until jurong p...|\n",
      "|  0.0|Ok lar... Joking ...|\n",
      "|  0.0|U dun say so earl...|\n",
      "|  0.0|Nah I don't think...|\n",
      "|  0.0|Even my brother i...|\n",
      "|  0.0|As per your reque...|\n",
      "|  0.0|I'm gonna be home...|\n",
      "|  0.0|I've been searchi...|\n",
      "|  0.0|I HAVE A DATE ON ...|\n",
      "|  0.0|Oh k...i'm watchi...|\n",
      "|  0.0|Eh u remember how...|\n",
      "|  0.0|Fine if thats th...|\n",
      "|  0.0|Is that seriously...|\n",
      "|  0.0|I‘m going to try ...|\n",
      "|  0.0|So ü pay first la...|\n",
      "|  0.0|Aft i finish my l...|\n",
      "|  0.0|Ffffffffff. Alrig...|\n",
      "|  0.0|Just forced mysel...|\n",
      "|  0.0|Lol your always s...|\n",
      "|  0.0|Did you catch the...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spamDF = spSession.createDataFrame(spamRRR2, [\"label\", \"message\"])\n",
    "spamDF.cache()\n",
    "spamDF.select(\"*\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento de Linguagem Natural\n",
    "* Aplicação do TF-IDF\n",
    "* TF - Term Frequency\n",
    "* IDF - Inverse Document Frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menor estrutura dentro de um texto\n",
    "tokenizer = Tokenizer(inputCol=\"message\", outputCol=\"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"tempfeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol = hashingTF.getOutputCol(), outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = spamDF.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "730"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages = [tokenizer, hashingTF, idf, classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=0.0, message='4 oclock at mine. Just to bash out a flat plan.', words=['4', 'oclock', 'at', 'mine.', 'just', 'to', 'bash', 'out', 'a', 'flat', 'plan.'], tempfeatures=SparseVector(262144, {10269: 1.0, 37542: 1.0, 38107: 1.0, 97171: 1.0, 114290: 1.0, 140390: 1.0, 140854: 1.0, 176964: 1.0, 205044: 1.0, 227410: 1.0, 233878: 1.0}), features=SparseVector(262144, {10269: 6.5944, 37542: 6.5944, 38107: 6.5944, 97171: 2.7026, 114290: 6.5944, 140390: 3.0681, 140854: 6.5944, 176964: 3.1287, 205044: 1.0034, 227410: 1.3317, 233878: 2.6824}), rawPrediction=DenseVector([-535.5643, -528.3838]), probability=DenseVector([0.0008, 0.9992]), prediction=1.0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.transform(df_test)\n",
    "predictions.select(\"*\").take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label',\n",
       " 'message',\n",
       " 'words',\n",
       " 'tempfeatures',\n",
       " 'features',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction',\n",
    "    labelCol='label',\n",
    "    metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|  126|\n",
      "|  0.0|       1.0|   13|\n",
      "|  1.0|       0.0|   14|\n",
      "|  0.0|       0.0|  117|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.groupBy(\"label\", \"prediction\").count().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
